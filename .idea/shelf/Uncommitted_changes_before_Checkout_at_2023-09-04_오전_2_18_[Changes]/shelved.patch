Index: path_config.yaml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\r\n#필요한 이미지 데이터셋의 경로를 담은 파일\r\n\r\nhandphone_image_path : \"C:\\\\Users\\\\mirun\\\\PycharmProjects\\\\PhotoTimestamp-AI\\\\for_vision\\\\handphone\"\r\nanimal_face : \"C:\\\\Users\\\\mirun\\\\PycharmProjects\\\\PhotoTimestamp-AI\\\\for_vision\\\\animal_face\\\\classification_image\"
===================================================================
diff --git a/path_config.yaml b/path_config.yaml
--- a/path_config.yaml	
+++ b/path_config.yaml	
@@ -2,4 +2,6 @@
 #필요한 이미지 데이터셋의 경로를 담은 파일
 
 handphone_image_path : "C:\\Users\\mirun\\PycharmProjects\\PhotoTimestamp-AI\\for_vision\\handphone"
-animal_face : "C:\\Users\\mirun\\PycharmProjects\\PhotoTimestamp-AI\\for_vision\\animal_face\\classification_image"
\ No newline at end of file
+animal_face_image_path : "C:\\Users\\mirun\\PycharmProjects\\PhotoTimestamp-AI\\for_vision\\animal_face\\classification_image"
+puppy_categories : "C:\\Users\\mirun\\PycharmProjects\\PhotoTimestamp-AI\\for_vision\\Puppy_category\\images\\Images"
+timetable_categories : "C:\\Users\\mirun\\PycharmProjects\\PhotoTimestamp-AI\\test_git\\LabelClassify\\DS\\mirflickr25k\\images"
Index: Get_ready_photo.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>import os\r\nfrom datetime import datetime\r\nimport shutil\r\nfrom PIL import Image\r\nfrom PIL.ExifTags import TAGS\r\n\r\n\r\nclass datasetIntoSmallDir:\r\n\r\n    def __init__(self,root_dir):\r\n        self.root_dir = root_dir\r\n\r\n    @staticmethod\r\n    def day_time_classify(dt):\r\n        season_times = {\r\n            \"Spring\": [(5, 34), (12, 33), (12, 34), (19, 35)],\r\n            \"Summer\": [(4, 58), (12, 34), (12, 34), (20, 9)],\r\n            \"Autumn\": [(6, 18), (12, 23), (12, 23), (18, 26)],\r\n            \"Winter\": [(7, 5), (12, 37), (12, 37), (18, 10)]\r\n        }\r\n        if dt.month in [3, 4, 5]:\r\n            season = \"Spring\"\r\n        elif dt.month in [6, 7, 8]:\r\n            season = \"Summer\"\r\n        elif dt.month in [9, 10, 11]:\r\n            season = \"Autumn\"\r\n        else:\r\n            season = \"Winter\"\r\n        morning_start, morning_end, afternoon_start, afternoon_end = season_times[season]\r\n\r\n        if (dt.hour == morning_start[0] and dt.minute >= morning_start[1]) or \\\r\n                (morning_start[0] < dt.hour < morning_end[0]) or \\\r\n                (dt.hour == morning_end[0] and dt.minute <= morning_end[1]):\r\n            return f\"{season}_Morning\"\r\n        elif (dt.hour == afternoon_start[0] and dt.minute >= afternoon_start[1]) or \\\r\n                (afternoon_start[0] < dt.hour < afternoon_end[0]) or \\\r\n                (dt.hour == afternoon_end[0] and dt.minute <= afternoon_end[1]):\r\n            return f\"{season}_Afternoon\"\r\n        else:\r\n            return f\"{season}_Night\"\r\n\r\n    def divide_into_groups_by_daytime(self):\r\n        folder = os.listdir(self.root_dir)\r\n        for file in folder:\r\n            image_path = os.path.join(self.root_dir, file)\r\n            try:\r\n                img = Image.open(image_path)\r\n                img_info = img.getexif()\r\n                if img_info and TAGS.get(306,306) in img_info:\r\n                    dt_str = img_info[TAGS.get(306, 306)]\r\n                    dt = datetime.strptime(dt_str, '%Y:%m:%d %H:%M:%S')\r\n                    destination_folder = os.path.join(self.root_dir,self.day_time_classify(dt))\r\n                    if not os.path.exists(destination_folder):\r\n                        os.mkdir(destination_folder)\r\n                    shutil.move(image_path, destination_folder)\r\n                img.close()\r\n            except:\r\n                print(f\"{file}는 처리할 수 없습니다.\")\r\n\r\n\r\n\r\nif __name__==\"__main__\":\r\n    divide = datasetIntoSmallDir(\"C:\\\\Users\\\\mirun\\\\PycharmProjects\\\\PhotoTimestamp-AI\\\\image_Dataset\")\r\n    divide.divide_into_groups_by_daytime()\r\n\r\n\r\n\r\n\r\n\r\n
===================================================================
diff --git a/Get_ready_photo.py b/Get_ready_photo.py
--- a/Get_ready_photo.py	
+++ b/Get_ready_photo.py	
@@ -49,7 +49,7 @@
                 if img_info and TAGS.get(306,306) in img_info:
                     dt_str = img_info[TAGS.get(306, 306)]
                     dt = datetime.strptime(dt_str, '%Y:%m:%d %H:%M:%S')
-                    destination_folder = os.path.join(self.root_dir,self.day_time_classify(dt))
+                    destination_folder = os.path.join(self.root_dir, self.day_time_classify(dt))
                     if not os.path.exists(destination_folder):
                         os.mkdir(destination_folder)
                     shutil.move(image_path, destination_folder)
Index: model.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\r\nfrom keras import Sequential\r\nfrom keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D\r\nfrom keras import regularizers\r\n\r\n\r\nclass ModelBuilder:\r\n    def __init__(self, base_hidden_units, weight_decay, image_info):\r\n        self.base_hidden_units = base_hidden_units\r\n        self.weight_decay = weight_decay\r\n        self.input_width = image_info.image_width\r\n        self.input_height = image_info.image_height\r\n\r\n    def build(self):\r\n        model = Sequential()  # (차례대로 층을 추가하는)순차형 모델 초기화\r\n\r\n        # conv1\r\n        model.add(Conv2D(self.base_hidden_units, kernel_size=3, padding='same',\r\n                         kernel_regularizer=regularizers.l2(self.weight_decay), input_shape=(self.input_width,\r\n                                                                                             self.input_height, 3)))\r\n        model.add(Activation('relu'))\r\n        # conv2\r\n        model.add(Conv2D(self.base_hidden_units, kernel_size=3, padding='same',\r\n                         kernel_regularizer=regularizers.l2(self.weight_decay)))\r\n        model.add(Activation('relu'))\r\n        # POOL1\r\n        model.add(MaxPooling2D(pool_size=(2, 2)))\r\n        model.add(Dropout(0.3))\r\n        # conv3\r\n        model.add(Conv2D(self.base_hidden_units * 2, kernel_size=3, padding='same',\r\n                         kernel_regularizer=regularizers.l2(self.weight_decay)))\r\n        model.add(Activation('relu'))\r\n        # conv4\r\n        model.add(Conv2D(self.base_hidden_units * 2, kernel_size=3, padding='same',\r\n                         kernel_regularizer=regularizers.l2(self.weight_decay)))\r\n        model.add(Activation('relu'))\r\n        # POOL2\r\n        model.add(MaxPooling2D(pool_size=(2, 2)))\r\n        # conv5\r\n        model.add(Conv2D(self.base_hidden_units * 4, kernel_size=3, padding='same',\r\n                         kernel_regularizer=regularizers.l2(self.weight_decay)))\r\n        model.add(Activation('relu'))\r\n        # conv6\r\n        model.add(Conv2D(self.base_hidden_units * 4, kernel_size=3, padding='same',\r\n                         kernel_regularizer=regularizers.l2(self.weight_decay)))\r\n        model.add(Activation('relu'))\r\n        # POOL3\r\n        model.add(MaxPooling2D(pool_size=(2, 2)))\r\n        model.add(Dropout(0.4))\r\n        # FC1\r\n        model.add(Flatten())\r\n        model.add(Dense(100, activation='relu'))\r\n        # FC2\r\n        model.add(Dense(4, activation='softmax'))\r\n        model.summary()\r\n        return model\r\n
===================================================================
diff --git a/model.py b/model.py
--- a/model.py	
+++ b/model.py	
@@ -2,7 +2,8 @@
 from keras import Sequential
 from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, Conv2D, MaxPooling2D
 from keras import regularizers
-
+import tensorflow_hub as hub
+import tensorflow as tf
 
 class ModelBuilder:
     def __init__(self, base_hidden_units, weight_decay, image_info):
@@ -12,45 +13,57 @@
         self.input_height = image_info.image_height
 
     def build(self):
-        model = Sequential()  # (차례대로 층을 추가하는)순차형 모델 초기화
+        Model_URL = 'https://kaggle.com/models/google/resnet-v2/frameworks/TensorFlow2/variations/50-classification/versions/2'
+
+        # 입력 텐서 정의
+        input_tensor = tf.keras.layers.Input(shape=(self.input_width, self.input_height, 3))
 
-        # conv1
-        model.add(Conv2D(self.base_hidden_units, kernel_size=3, padding='same',
-                         kernel_regularizer=regularizers.l2(self.weight_decay), input_shape=(self.input_width,
-                                                                                             self.input_height, 3)))
-        model.add(Activation('relu'))
-        # conv2
-        model.add(Conv2D(self.base_hidden_units, kernel_size=3, padding='same',
-                         kernel_regularizer=regularizers.l2(self.weight_decay)))
-        model.add(Activation('relu'))
-        # POOL1
-        model.add(MaxPooling2D(pool_size=(2, 2)))
-        model.add(Dropout(0.3))
-        # conv3
-        model.add(Conv2D(self.base_hidden_units * 2, kernel_size=3, padding='same',
-                         kernel_regularizer=regularizers.l2(self.weight_decay)))
-        model.add(Activation('relu'))
-        # conv4
-        model.add(Conv2D(self.base_hidden_units * 2, kernel_size=3, padding='same',
-                         kernel_regularizer=regularizers.l2(self.weight_decay)))
-        model.add(Activation('relu'))
-        # POOL2
-        model.add(MaxPooling2D(pool_size=(2, 2)))
-        # conv5
-        model.add(Conv2D(self.base_hidden_units * 4, kernel_size=3, padding='same',
-                         kernel_regularizer=regularizers.l2(self.weight_decay)))
-        model.add(Activation('relu'))
-        # conv6
-        model.add(Conv2D(self.base_hidden_units * 4, kernel_size=3, padding='same',
-                         kernel_regularizer=regularizers.l2(self.weight_decay)))
-        model.add(Activation('relu'))
-        # POOL3
-        model.add(MaxPooling2D(pool_size=(2, 2)))
-        model.add(Dropout(0.4))
-        # FC1
-        model.add(Flatten())
-        model.add(Dense(100, activation='relu'))
-        # FC2
-        model.add(Dense(4, activation='softmax'))
+        # TensorFlow Hub 모델 사용
+        hub_layer = hub.KerasLayer(Model_URL, trainable=True)(input_tensor)
+
+        # 다음 레이어 추가
+        output_tensor = tf.keras.layers.Dense(12, activation="softmax")(hub_layer)
+
+        # 모델 생성
+        model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)
+        #
+        # # conv1
+        # model.add(Conv2D(self.base_hidden_units, kernel_size=3, padding='same',
+        #                  kernel_regularizer=regularizers.l2(self.weight_decay), input_shape=(self.input_width,
+        #                                                                                      self.input_height, 3)))
+        # model.add(Activation('relu'))
+        # # conv2
+        # model.add(Conv2D(self.base_hidden_units, kernel_size=3, padding='same',
+        #                  kernel_regularizer=regularizers.l2(self.weight_decay)))
+        # model.add(Activation('relu'))
+        # # POOL1
+        # model.add(MaxPooling2D(pool_size=(2, 2)))
+        # model.add(Dropout(0.3))
+        # # conv3
+        # model.add(Conv2D(self.base_hidden_units * 2, kernel_size=3, padding='same',
+        #                  kernel_regularizer=regularizers.l2(self.weight_decay)))
+        # model.add(Activation('relu'))
+        # # conv4
+        # model.add(Conv2D(self.base_hidden_units * 2, kernel_size=3, padding='same',
+        #                  kernel_regularizer=regularizers.l2(self.weight_decay)))
+        # model.add(Activation('relu'))
+        # # POOL2
+        # model.add(MaxPooling2D(pool_size=(2, 2)))
+        # # conv5
+        # model.add(Conv2D(self.base_hidden_units * 4, kernel_size=3, padding='same',
+        #                  kernel_regularizer=regularizers.l2(self.weight_decay)))
+        # model.add(Activation('relu'))
+        # # conv6
+        # model.add(Conv2D(self.base_hidden_units * 4, kernel_size=3, padding='same',
+        #                  kernel_regularizer=regularizers.l2(self.weight_decay)))
+        # model.add(Activation('relu'))
+        # # POOL3
+        # model.add(MaxPooling2D(pool_size=(2, 2)))
+        # model.add(Dropout(0.4))
+        # # FC1
+        # model.add(Flatten())
+        # model.add(Dense(100, activation='relu'))
+        # # FC2
+        # model.add(Dense(120, activation='softmax'))
         model.summary()
         return model
Index: pipeline.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>'''\r\n이미지 분류과정에 필요한 모든 클래스를 한번에 모아서 만든 프레임워크가 되고싶은 클래스\r\n'''\r\nimport os\r\nos.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\r\nfrom pre_proc import PreProcessing, ImageInfo, DatasetInfo\r\nfrom model import ModelBuilder\r\nfrom trainer import ModelTrainer\r\nfrom data_loader import DatasetLoader\r\nimport sys\r\nimport pickle\r\nimport tensorflow as tf\r\nfrom final_test import Debugger\r\nimport yaml\r\n\r\nclass Pipeline:\r\n    def __init__(self):\r\n        self.test_ds = None\r\n        self.valid_ds = None\r\n        self.train_ds = None\r\n        self.model = None\r\n        self.image_info = ImageInfo(image_height=224, image_width=224)\r\n        with open('path_config.yaml', 'r',  encoding='utf-8') as file:\r\n            config = yaml.safe_load(file)\r\n        handphone_image_path_from_yaml = config['handphone_image_path']\r\n        # animal_face_image_path_from_yaml = config['animal_face_image_path']\r\n\r\n        self.dataset_info = DatasetInfo(train_ratio=0.8, valid_ratio=0.1, test_ratio=0.1, batch_size=32, seed=188)\r\n        self.image_path = handphone_image_path_from_yaml\r\n        self.dataloader = DatasetLoader(self.image_path, self.image_info, self.dataset_info)\r\n\r\n        self.modelbuilder = ModelBuilder(base_hidden_units=16, weight_decay=1e-4, image_info=self.image_info)\r\n        self.modeltrainer = None\r\n\r\n\r\n\r\n    def image_load(self):\r\n        self.train_ds, self.valid_ds, self.test_ds = self.dataloader.get_datasets()\r\n        self.preprocessor = PreProcessing(self.train_ds, self.valid_ds, self.test_ds)\r\n\r\n    def preprocess(self,methods=None):\r\n        if methods is None:\r\n            methods = [self.preprocessor.normalize,self.preprocessor.shuffle]\r\n        self.preprocessor.set_preprocess_methods(methods)\r\n        self.train_ds, self.valid_ds, self.test_ds = self.preprocessor.get_dataset_through_preprocessed()\r\n    def config_model(self):\r\n        self.model = self.modelbuilder.build()\r\n        self.modeltrainer = ModelTrainer(self.model)\r\n\r\n    def fit(self, epochs=15):\r\n        trained_model, training_history = self.modeltrainer.fit(self.train_ds, self.valid_ds, epochs)\r\n        return trained_model, training_history\r\n\r\n\r\ndef main():\r\n    clmo = Pipeline()\r\n    print(\"학습 모드\")\r\n    clmo.image_load()\r\n    preprocess_methods = [clmo.preprocessor.normalize, clmo.preprocessor.shuffle]\r\n    clmo.preprocess(preprocess_methods)\r\n    clmo.config_model()\r\n    trained_model, training_history = clmo.fit(epochs=10)\r\n\r\n    trained_model.save('model.h5')\r\n    with open('training_history.pkl', 'wb') as file:\r\n        pickle.dump(training_history.history, file)\r\n    '''\r\n    training_history.pkl'라는 파일을 바이너리 쓰기 모드('wb')로 연다. \r\n    열린 파일 객체를 file 변수로 참조.\r\n    pickle.dump 함수는 첫 번째 인자로 주어진 객체를 직렬화하여 두 번째 인자로 주어진 파일 객체에 저장.\r\n    training_history.history 객체를 file에 직렬화하여 저장.\r\n    그나저나 이렇게 쓰면 약간 지저분해지는것 같은데..\r\n    '''\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n\r\n
===================================================================
diff --git a/pipeline.py b/pipeline.py
--- a/pipeline.py	
+++ b/pipeline.py	
@@ -22,11 +22,13 @@
         self.image_info = ImageInfo(image_height=224, image_width=224)
         with open('path_config.yaml', 'r',  encoding='utf-8') as file:
             config = yaml.safe_load(file)
-        handphone_image_path_from_yaml = config['handphone_image_path']
-        # animal_face_image_path_from_yaml = config['animal_face_image_path']
+        #handphone_image_path_from_yaml = config['handphone_image_path']
+        #animal_face_image_path_from_yaml = config['animal_face_image_path']
+        #puppy_categories_image_path_from_yaml = config['puppy_categories']
+        timetable_categories_from_yaml = config['timetable_categories']
 
         self.dataset_info = DatasetInfo(train_ratio=0.8, valid_ratio=0.1, test_ratio=0.1, batch_size=32, seed=188)
-        self.image_path = handphone_image_path_from_yaml
+        self.image_path = timetable_categories_from_yaml
         self.dataloader = DatasetLoader(self.image_path, self.image_info, self.dataset_info)
 
         self.modelbuilder = ModelBuilder(base_hidden_units=16, weight_decay=1e-4, image_info=self.image_info)
